<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ossama Ahmed</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Ossama Ahmed</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 09 Oct 2020 23:17:37 +0200</lastBuildDate>
    <image>
      <url>/images/icon_hub02f11719440bf94480d1ab9e24c040b_69343_512x512_fill_lanczos_center_2.png</url>
      <title>Ossama Ahmed</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Real Robot Challenge</title>
      <link>/project/real_robot/</link>
      <pubDate>Fri, 09 Oct 2020 23:17:37 +0200</pubDate>
      <guid>/project/real_robot/</guid>
      <description>&lt;p&gt;Experimentation on real robots is very costly in terms of time and money. For this reason, a large part of the reinforcement learning community uses simulators, such as those available through OpenAI Gym, to develop and benchmark algorithms. However, insights gained in simulation do not necessarily translate to real robots, in particular for tasks involving complex interaction with the environment.&lt;/p&gt;
&lt;p&gt;The purpose of this competition is to alleviate this problem by allowing participants to experiment on a real robot as easily as on a simulator. As tasks, we propose a number of dexterous manipulation problems, such as pushing, grasping, flipping and spinning objects.
We developed robot hardware and software which is suitable for this setup. The robots will be hosted at our institute and participants will execute their algorithms remotely, through a convenient and simple interface.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Causal World</title>
      <link>/project/causal_world/</link>
      <pubDate>Thu, 08 Oct 2020 22:56:48 +0200</pubDate>
      <guid>/project/causal_world/</guid>
      <description>&lt;p&gt;Despite recent successes of reinforcement learning (RL), it remains a challenge
for agents to transfer learned skills to related environments. To facilitate research
addressing this, we propose CausalWorld, a benchmark for causal structure and
transfer learning in a robotic manipulation environment. The environment is a
simulation of an open-source robotic platform, hence offering the possibility of
sim-to-real transfer. Tasks consist of constructing 3D shapes from a given set
of blocks - inspired by how children learn to build complex structures. The key
strength of CausalWorld is that it provides a combinatorial family of such tasks
with common causal structure and underlying factors (including, e.g., robot and
object masses, colors, sizes). The user (or the agent) may intervene on all causal
variables, which allows for fine-grained control over how similar different tasks
(or task distributions) are. One can thus easily define training and evaluation
distributions of a desired difficulty level, targeting a specific form of generalization (e.g., only changes in appearance or object mass). Further, this common
parametrization facilitates defining curricula by interpolating between an initial
and a target task. While users may define their own task distributions, we present
eight meaningful distributions as concrete benchmarks, ranging from simple to
very challenging, all of which require long-horizon planning and precise low-level
motor control at the same time. Finally, we provide baseline results for a subset of
these tasks on distinct training curricula and corresponding evaluation protocols,
verifying the feasibility of the tasks in this benchmark.1&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CAUSALWORLD: A ROBOTIC MANIPULATION BENCHMARK FOR CAUSAL STRUCTURE AND TRANSFER LEARNING</title>
      <link>/publication/causal/</link>
      <pubDate>Fri, 02 Oct 2020 00:00:00 +0000</pubDate>
      <guid>/publication/causal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Blackbox MPC</title>
      <link>/project/blackbox_mpc/</link>
      <pubDate>Sun, 09 Feb 2020 23:23:28 +0200</pubDate>
      <guid>/project/blackbox_mpc/</guid>
      <description>&lt;p&gt;The code repository provides a framework of different derivative-free optimizers which can be used in conjuction with a model predictive controller and a learned dynamics model to control an agent in a mujoco or a gym environment.&lt;/p&gt;
&lt;p&gt;The code was written as part of a research project at the Learning and Adaptive Systems Lab @ETH Zurich. Overall, the aim of this package is to enable performing optimal control with model-predictive control on any mujoco or gym environment in couple of steps.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep 3D Human Pose Estimation</title>
      <link>/project/pose_estimation/</link>
      <pubDate>Wed, 09 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/project/pose_estimation/</guid>
      <description>&lt;p&gt;Recent advances in scientific computing hardware and the increased availability of public datasets have allowed deep learning to sky-
rocket the performance of the state-of-the-art models for the problem of 3D Human Pose Estimation. We propose a pipeline that comprises one of the most recent approaches, namely the High-
Resolution Network, combined with a low-weight baseline model for extracting the 3D skeleton of human subjects of the Human3.6M dataset. Our approach splits the challenges of the task in image-
related, and geometric-related, where each group is processed by a model specialized in one of the two. We show that our model
achieves good results despite a relatively low training time (around 24 hours), although it still has some trouble at discriminating some
of the upper and lower limbs. We finally propose further training strategies to help the model deal with its current limitations.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Effect of Behavioral Cloning on Policy Gradient Methods</title>
      <link>/project/anymal/</link>
      <pubDate>Wed, 09 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/project/anymal/</guid>
      <description>&lt;p&gt;With the increasing complexity of robots and the environments they interact with,
crafting manual locomotion controllers becomes a challenging task to achieve. As evident from the recent research in this field, reinforcement learning (RL) contin-
ues to emerge as an attractive solution for learning locomotion policies in high-
dimensional continuous domains. However, despite the impressive results of RL so far, its methods suffer from sample inefficiency and sensitivity to hyper-parameters;
including but not limited to reward functions and policy initialization. Therefore, new approaches are needed to decrease the effort spent on reward engineering, which
is crucial in the success of the aforementioned methods. Drawing inspiration from
nature, it is often easier for an agent to learn a desired behaviour from a teacher demonstrating it rather than attempt to learn it from scratch; a process called imitation learning. This thesis explores the possibilities of warming up a policy using behavioural cloning (BC) - a type of imitation learning - to avoid getting stuck in
a poor suboptimal minima and to decrease the effort spent on reward engineering. In this work we compare training an RL agent using policy gradient methods starting from a randomly initialized policy as opposed to initializing the policy through BC. This comparison is done in simulation using ANYmal robot, a sophisticated medium-dog-sized quadrupedal system. The results show that initializing a policy through BC enables capturing some of the desired behaviour features early-on without explicitly defining them into the RL problem formulation. We furthermore show that using BC for warming up produces a more robust policy - during training - towards modifications in reward functions as well as observation space, which together they form the cost manifold that policy gradient methods optimize.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Local Exploration Based on TSDF</title>
      <link>/project/plr/</link>
      <pubDate>Wed, 09 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/project/plr/</guid>
      <description>&lt;p&gt;In order to enable robots to explore and assist in complex unknown environments, we propose a learning-based approach for exploring unknown cluttered environments. The underlying exploration model is an end to end neural
network policy trained using reinforcement learning (RL) to use the euclidean
signed distance fields (ESDFs) local map to efficiently navigate and explore the
surrounding environment with no prior information about the environment itself.
We evaluate our approach using different RL algorithms and reward functions.
We show in simulation that the proposed exploration approach can effectively
determine appropiate frontier locations to navigate to while being robust to different environment layouts. We also show that compressing the ESDF local map to a
meaningful descriptor accelarates the training process.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Online Adaptation using Graph Networks</title>
      <link>/project/meta_rl/</link>
      <pubDate>Wed, 09 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/project/meta_rl/</guid>
      <description>&lt;p&gt;Despite the recent success of deep reinforcement learning (RL), current RL algorithms are typically unable to generalize well to unseen environment changes such as crippling or external perturbations. We hypothesize that this is due to the absence of inductive biases in these algorithms that would help transfer knowledge across
tasks. In this paper, we investigate the application of graph-based relational networks to overcome this limitation. Specifically, we use a graph neural network (GNN) to learn a forward model of the environment. We use the learned model in conjunction with a model-based controller, and compare our approach against existing model-free
and model-based approaches. Further, we provide insights into whether our approach helps improve generalization to new environments or not.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Duckie Town</title>
      <link>/project/duckie_town/</link>
      <pubDate>Tue, 09 Oct 2018 00:00:00 +0000</pubDate>
      <guid>/project/duckie_town/</guid>
      <description>&lt;p&gt;What would a self-driving car do if the car just in front it has malfunctioning break lights? What would it do if a kid suddenly lets go of his mother’s grasp and jumps into the road? What would it do if the sensors it uses for perception break down unexpectedly? All of these situations and more may be captured if the planning algorithms are planning for such uncertainties, which include the behavior of other agents in the environment as well as our perception of the environment itself.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sparse Monocular Visual Odometry Pipeline</title>
      <link>/project/visual_odometry/</link>
      <pubDate>Tue, 09 Oct 2018 00:00:00 +0000</pubDate>
      <guid>/project/visual_odometry/</guid>
      <description>&lt;p&gt;Successfully implemented a monocular visual odometry (VO) pipeline with the most essential features: initialization of 3D
landmarks, key point tracking between two frames, pose estimation using established 2D ↔ 3D correspondences, and
triangulation of new landmarks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Talk on Expected Policy Gradients</title>
      <link>/talk/my-talk-name/</link>
      <pubDate>Tue, 09 Oct 2018 00:00:00 +0000</pubDate>
      <guid>/talk/my-talk-name/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Telepresence System</title>
      <link>/project/capstone/</link>
      <pubDate>Mon, 12 Dec 2016 00:00:00 +0000</pubDate>
      <guid>/project/capstone/</guid>
      <description>&lt;p&gt;Successfully developed a Telepresence System that is equipped with high definition cameras remotely
connected to an Oculus Rift. The purpose of the Telepresence System is to allow the users to see as if they were physically
in place of the system itself. The project focused on three main areas: distortion removal, panoramic frame stitching and
high definition video streaming.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Enigma Machine</title>
      <link>/project/enigma/</link>
      <pubDate>Sun, 09 Oct 2016 00:00:00 +0000</pubDate>
      <guid>/project/enigma/</guid>
      <description>&lt;p&gt;Designed, built and tested a model of a digital Enigma Machine, a cipher machine used in WWII, on an FPGA board.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GoLite Compiler</title>
      <link>/project/go_lite/</link>
      <pubDate>Sun, 09 Oct 2016 00:00:00 +0000</pubDate>
      <guid>/project/go_lite/</guid>
      <description>&lt;p&gt;Designed a compiler for GoLite, a subset of the Go programming language. Built the entire compiler pipeline (parser, syntax tree,
type checker, code generator and optimizer), producing Java Byte Code as the target language.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>HUS AI agent</title>
      <link>/project/hus_ai/</link>
      <pubDate>Sun, 09 Oct 2016 00:00:00 +0000</pubDate>
      <guid>/project/hus_ai/</guid>
      <description>&lt;p&gt;This project studied the implementation of the TD-learning algorithm with the min-max search algorithm to develop an AI agent to play HUS board game which is from
the family of ”Mancala” games.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Catch the Flag Robot</title>
      <link>/project/catch_the_flag/</link>
      <pubDate>Fri, 09 Oct 2015 00:00:00 +0000</pubDate>
      <guid>/project/catch_the_flag/</guid>
      <description>&lt;p&gt;Led my team in developing an autonomous robot, in a team of 5 students, to compete against more than 120 engineering
students to play catch the flag game, where we ranked 3/25.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bomberman Game</title>
      <link>/project/bomberman/</link>
      <pubDate>Thu, 09 Oct 2014 00:00:00 +0000</pubDate>
      <guid>/project/bomberman/</guid>
      <description>&lt;p&gt;Implemented a modified version of this game with integrated account management system.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
