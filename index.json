[{"authors":["admin"],"categories":null,"content":"I have recently completed a MSc degree in Robotics, Systems and Control at ETH Zurich. Prior to that I worked at Qualcomm with the SNPE SDK team after finishing my undergrad in Software Engineering at McGill.\nMy interests lie in applying learning methods to robotics related problems. In particular, my main research goals entail enabling dynamical systems to efficiently and safely learn in real environments where they face high prior uncertainties.\nI currently work under the supervision of Prof. Yoshua Bengio on motion planning using model-based learning methods.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/ossama-ahmed/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ossama-ahmed/","section":"authors","summary":"I have recently completed a MSc degree in Robotics, Systems and Control at ETH Zurich. Prior to that I worked at Qualcomm with the SNPE SDK team after finishing my undergrad in Software Engineering at McGill.","tags":null,"title":"Ossama Ahmed","type":"authors"},{"authors":["Sean C. Smithson","Ossama S. Ahmed","Guang Yang","Warren J. Gross","Brett H. Meyer"],"categories":[],"content":"","date":1602318442,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602318442,"objectID":"c6a6cbb4f548adff00c34bf6974d876b","permalink":"/publication/neural/","publishdate":"2016-09-10T00:00:00Z","relpermalink":"/publication/neural/","section":"publication","summary":"Hardware and Algorithms for Learning On-a-chip (HALO) 2016, Workshop on, Nov 2016.","tags":[],"title":"Neural Networks Designing Neural Networks (Poster)","type":"publication"},{"authors":[],"categories":[],"content":"Experimentation on real robots is very costly in terms of time and money. For this reason, a large part of the reinforcement learning community uses simulators, such as those available through OpenAI Gym, to develop and benchmark algorithms. However, insights gained in simulation do not necessarily translate to real robots, in particular for tasks involving complex interaction with the environment.\nThe purpose of this competition is to alleviate this problem by allowing participants to experiment on a real robot as easily as on a simulator. As tasks, we propose a number of dexterous manipulation problems, such as pushing, grasping, flipping and spinning objects. We developed robot hardware and software which is suitable for this setup. The robots will be hosted at our institute and participants will execute their algorithms remotely, through a convenient and simple interface.\n","date":1602278257,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602278257,"objectID":"2cf16c845c4c26c6103e7806e5d67c09","permalink":"/project/real_robot/","publishdate":"2020-10-09T23:17:37+02:00","relpermalink":"/project/real_robot/","section":"project","summary":"Currently co-organizing a new real robotics challenge to advance the state-of-the-art in robotic manipulation, a key skill required to deploy robots in the real world. Where we host multiple robotic platforms at the Max Planck Institute for Intelligent Systems. Participants will submit their code as they would for a cluster, and it will then be executed automatically on our platforms. This will allow teams to gather hundreds of hours of real robot data with minimal effort.","tags":[],"title":"Real Robot Challenge","type":"project"},{"authors":[],"categories":[],"content":"Despite recent successes of reinforcement learning (RL), it remains a challenge for agents to transfer learned skills to related environments. To facilitate research addressing this, we propose CausalWorld, a benchmark for causal structure and transfer learning in a robotic manipulation environment. The environment is a simulation of an open-source robotic platform, hence offering the possibility of sim-to-real transfer. Tasks consist of constructing 3D shapes from a given set of blocks - inspired by how children learn to build complex structures. The key strength of CausalWorld is that it provides a combinatorial family of such tasks with common causal structure and underlying factors (including, e.g., robot and object masses, colors, sizes). The user (or the agent) may intervene on all causal variables, which allows for fine-grained control over how similar different tasks (or task distributions) are. One can thus easily define training and evaluation distributions of a desired difficulty level, targeting a specific form of generalization (e.g., only changes in appearance or object mass). Further, this common parametrization facilitates defining curricula by interpolating between an initial and a target task. While users may define their own task distributions, we present eight meaningful distributions as concrete benchmarks, ranging from simple to very challenging, all of which require long-horizon planning and precise low-level motor control at the same time. Finally, we provide baseline results for a subset of these tasks on distinct training curricula and corresponding evaluation protocols, verifying the feasibility of the tasks in this benchmark.1\n","date":1602190608,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602190608,"objectID":"28dded7c8b1ddf12a63533823d2cd5ea","permalink":"/project/causal_world/","publishdate":"2020-10-08T22:56:48+02:00","relpermalink":"/project/causal_world/","section":"project","summary":"CausalWorld is an open-source simulation framework and benchmark for causal structure and transfer learning in a robotic manipulation environment (powered by bullet) where tasks range from rather simple to extremely hard. Tasks consist of constructing 3D shapes from a given set of blocks - inspired by how children learn to build complex structures.","tags":[],"title":"Causal World","type":"project"},{"authors":["Ossama Ahmed","Frederik Träuble","Anirudh Goyal","Alexander Neitz","Manuel Wütrich","Yoshua Bengio","Bernhard Schölkopf","Stefan Bauer"],"categories":[],"content":"","date":1601596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601596800,"objectID":"1962bcc938ab2fc663cd6ebb0cff78fc","permalink":"/publication/causal/","publishdate":"2020-10-10T10:13:27+02:00","relpermalink":"/publication/causal/","section":"publication","summary":"Submitted to ICLR","tags":[],"title":"CausalWorld: A Robotics Manipulation Benchmark For Causal Structure And Transfer Learning","type":"publication"},{"authors":[],"categories":[],"content":"The code repository provides a framework of different derivative-free optimizers which can be used in conjuction with a model predictive controller and a learned dynamics model to control an agent in a mujoco or a gym environment.\nThe code was written as part of a research project at the Learning and Adaptive Systems Lab @ETH Zurich. Overall, the aim of this package is to enable performing optimal control with model-predictive control on any mujoco or gym environment in couple of steps.\n","date":1581283408,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581283408,"objectID":"7cea5d7e90100f1226406f5e781a5569","permalink":"/project/blackbox_mpc/","publishdate":"2020-02-09T23:23:28+02:00","relpermalink":"/project/blackbox_mpc/","section":"project","summary":"A framework of different derivative-free optimizers which can be used in conjunction  with a model predictive controller and a learned dynamics model to control an agent in a mujoco or a gym environment.","tags":[],"title":"Blackbox MPC","type":"project"},{"authors":[],"categories":[],"content":"Recent advances in scientific computing hardware and the increased availability of public datasets have allowed deep learning to sky- rocket the performance of the state-of-the-art models for the problem of 3D Human Pose Estimation. We propose a pipeline that comprises one of the most recent approaches, namely the High- Resolution Network, combined with a low-weight baseline model for extracting the 3D skeleton of human subjects of the Human3.6M dataset. Our approach splits the challenges of the task in image- related, and geometric-related, where each group is processed by a model specialized in one of the two. We show that our model achieves good results despite a relatively low training time (around 24 hours), although it still has some trouble at discriminating some of the upper and lower limbs. We finally propose further training strategies to help the model deal with its current limitations.\n","date":1570579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570579200,"objectID":"f0b39a6506a84b7342a386aee1777747","permalink":"/project/pose_estimation/","publishdate":"2019-10-09T00:00:00Z","relpermalink":"/project/pose_estimation/","section":"project","summary":"Proposed a pipeline that comprises one of the most recent approaches, namely the HighResolution Network combined with a lowweight baseline model for extracting the 3D skeleton of human subjects applied to the Human3.6M dataset; splitting the challenge to image-related and geometric-related tasks.","tags":[],"title":"Deep 3D Human Pose Estimation","type":"project"},{"authors":[],"categories":[],"content":"With the increasing complexity of robots and the environments they interact with, crafting manual locomotion controllers becomes a challenging task to achieve. As evident from the recent research in this field, reinforcement learning (RL) contin- ues to emerge as an attractive solution for learning locomotion policies in high- dimensional continuous domains. However, despite the impressive results of RL so far, its methods suffer from sample inefficiency and sensitivity to hyper-parameters; including but not limited to reward functions and policy initialization. Therefore, new approaches are needed to decrease the effort spent on reward engineering, which is crucial in the success of the aforementioned methods. Drawing inspiration from nature, it is often easier for an agent to learn a desired behaviour from a teacher demonstrating it rather than attempt to learn it from scratch; a process called imitation learning. This thesis explores the possibilities of warming up a policy using behavioural cloning (BC) - a type of imitation learning - to avoid getting stuck in a poor suboptimal minima and to decrease the effort spent on reward engineering. In this work we compare training an RL agent using policy gradient methods starting from a randomly initialized policy as opposed to initializing the policy through BC. This comparison is done in simulation using ANYmal robot, a sophisticated medium-dog-sized quadrupedal system. The results show that initializing a policy through BC enables capturing some of the desired behaviour features early-on without explicitly defining them into the RL problem formulation. We furthermore show that using BC for warming up produces a more robust policy - during training - towards modifications in reward functions as well as observation space, which together they form the cost manifold that policy gradient methods optimize.\n","date":1570579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570579200,"objectID":"1e8ea1b66c6517197fa432b2787573a8","permalink":"/project/anymal/","publishdate":"2019-10-09T00:00:00Z","relpermalink":"/project/anymal/","section":"project","summary":"With the increasing complexity of robots and the environments they interact with, crafting manual locomotion controllers becomes a challenging task to achieve. As evident from the recent research in this field, reinforcement learning (RL) contin- ues to emerge as an attractive solution for learning locomotion policies in high- dimensional continuous domains.","tags":[],"title":"Effect of Behavioral Cloning on Policy Gradient Methods","type":"project"},{"authors":[],"categories":[],"content":"In order to enable robots to explore and assist in complex unknown environments, we propose a learning-based approach for exploring unknown cluttered environments. The underlying exploration model is an end to end neural network policy trained using reinforcement learning (RL) to use the euclidean signed distance fields (ESDFs) local map to efficiently navigate and explore the surrounding environment with no prior information about the environment itself. We evaluate our approach using different RL algorithms and reward functions. We show in simulation that the proposed exploration approach can effectively determine appropiate frontier locations to navigate to while being robust to different environment layouts. We also show that compressing the ESDF local map to a meaningful descriptor accelarates the training process.\n","date":1570579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570579200,"objectID":"8c72b8c21581f774b7d57d82ae0d3270","permalink":"/project/plr/","publishdate":"2019-10-09T00:00:00Z","relpermalink":"/project/plr/","section":"project","summary":"Most current exploration algorithms are based on heuristics and sampling/evaluating many potential viewpoints. The goal of this work is to learn an ideal motion to maximize the known space based on a local map representation.","tags":["Robotics","Reinforcement Learning"],"title":"Local Exploration Based on TSDF","type":"project"},{"authors":[],"categories":[],"content":"Despite the recent success of deep reinforcement learning (RL), current RL algorithms are typically unable to generalize well to unseen environment changes such as crippling or external perturbations. We hypothesize that this is due to the absence of inductive biases in these algorithms that would help transfer knowledge across tasks. In this paper, we investigate the application of graph-based relational networks to overcome this limitation. Specifically, we use a graph neural network (GNN) to learn a forward model of the environment. We use the learned model in conjunction with a model-based controller, and compare our approach against existing model-free and model-based approaches. Further, we provide insights into whether our approach helps improve generalization to new environments or not.\n","date":1570579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570579200,"objectID":"3b9ce437ab3bc4f0620abb023ecca3fd","permalink":"/project/meta_rl/","publishdate":"2019-10-09T00:00:00Z","relpermalink":"/project/meta_rl/","section":"project","summary":"Considered learning online adaptation in a model-based reinforcement learning context where we train a dynamics model, implemented as a Graph Neural Network, in conjunction with using MPC to control a system where the controller adapts to changes in the environment or tasks.","tags":[],"title":"Online Adaptation using Graph Networks","type":"project"},{"authors":[],"categories":["Robotics"],"content":"What would a self-driving car do if the car just in front it has malfunctioning break lights? What would it do if a kid suddenly lets go of his mother’s grasp and jumps into the road? What would it do if the sensors it uses for perception break down unexpectedly? All of these situations and more may be captured if the planning algorithms are planning for such uncertainties, which include the behavior of other agents in the environment as well as our perception of the environment itself.\n","date":1539043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539043200,"objectID":"ad75c01ef3d56b88da414e8354ff1d49","permalink":"/project/duckie_town/","publishdate":"2018-10-09T00:00:00Z","relpermalink":"/project/duckie_town/","section":"project","summary":"Successfully implemented a path planner and a velocity profiler for duckiebots as part of duckietown, a robotics outreach and educational platform, while taking into account various sources of uncertainty.","tags":["Planning","Robotics"],"title":"Duckie Town","type":"project"},{"authors":[],"categories":[],"content":"Successfully implemented a monocular visual odometry (VO) pipeline with the most essential features: initialization of 3D landmarks, key point tracking between two frames, pose estimation using established 2D ↔ 3D correspondences, and triangulation of new landmarks.\n","date":1539043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539043200,"objectID":"95b2b6dbae445a1451583efde9a04369","permalink":"/project/visual_odometry/","publishdate":"2018-10-09T00:00:00Z","relpermalink":"/project/visual_odometry/","section":"project","summary":"Successfully implemented a monocular visual odometry (VO) pipeline with the most essential features: initialization of 3D landmarks, key point tracking between two frames, pose estimation using established 2D ↔ 3D correspondences, and triangulation of new landmarks.","tags":[],"title":"Sparse Monocular Visual Odometry Pipeline","type":"project"},{"authors":[],"categories":null,"content":"","date":1539043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539043200,"objectID":"becc88d711f702f2f2ceddaa3781c617","permalink":"/talk/my-talk-name/","publishdate":"2020-10-09T14:17:53+02:00","relpermalink":"/talk/my-talk-name/","section":"talk","summary":"Paper review of expected policy gradients https://arxiv.org/pdf/1706.05374.pdf by Kamil Ciosek and Shimon Whiteson.","tags":[],"title":"Talk on Expected Policy Gradients","type":"talk"},{"authors":[],"categories":[],"content":"Successfully developed a Telepresence System that is equipped with high definition cameras remotely connected to an Oculus Rift. The purpose of the Telepresence System is to allow the users to see as if they were physically in place of the system itself. The project focused on three main areas: distortion removal, panoramic frame stitching and high definition video streaming.\n","date":1481500800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481500800,"objectID":"13f4b92cb34ac5dba5bcd874075c768d","permalink":"/project/capstone/","publishdate":"2016-12-12T00:00:00Z","relpermalink":"/project/capstone/","section":"project","summary":"Successfully developed a Telepresence System that is equipped with high definition cameras remotely connected to an Oculus Rift. The purpose of the Telepresence System is to allow the users to see as if they were physically in place of the system itself. The project focused on three main areas: distortion removal, panoramic frame stitching and high definition video streaming.","tags":[],"title":"Telepresence System","type":"project"},{"authors":[],"categories":[],"content":"Designed, built and tested a model of a digital Enigma Machine, a cipher machine used in WWII, on an FPGA board.\n","date":1475971200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475971200,"objectID":"2b9736b2dd9875c4fa0ede86497f9107","permalink":"/project/enigma/","publishdate":"2016-10-09T00:00:00Z","relpermalink":"/project/enigma/","section":"project","summary":"Designed, built and tested a model of a digital Enigma Machine, a cipher machine used in WWII, on an FPGA board.","tags":[],"title":"Enigma Machine","type":"project"},{"authors":[],"categories":[],"content":"Designed a compiler for GoLite, a subset of the Go programming language. Built the entire compiler pipeline (parser, syntax tree, type checker, code generator and optimizer), producing Java Byte Code as the target language.\n","date":1475971200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475971200,"objectID":"80925befd53225be3fc53ae7ba29cd50","permalink":"/project/go_lite/","publishdate":"2016-10-09T00:00:00Z","relpermalink":"/project/go_lite/","section":"project","summary":"Designed a compiler for GoLite, a subset of the Go programming language. Built the entire compiler pipeline (parser, syntax tree, type checker, code generator and optimizer), producing Java Byte Code as the target language.","tags":[],"title":"GoLite Compiler","type":"project"},{"authors":[],"categories":[],"content":"This project studied the implementation of the TD-learning algorithm with the min-max search algorithm to develop an AI agent to play HUS board game which is from the family of ”Mancala” games.\n","date":1475971200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475971200,"objectID":"e47dcf8477e04fb1ecfd90d082cc4930","permalink":"/project/hus_ai/","publishdate":"2016-10-09T00:00:00Z","relpermalink":"/project/hus_ai/","section":"project","summary":"Created an Artificial Intelligence agent to compete against more than 200 engineering students to play the HUS game, which is from the family of “Mancala Games”, using Reinforcement Learning Techniques. The agent ranked from the top 10%.","tags":[],"title":"HUS AI agent","type":"project"},{"authors":[],"categories":[],"content":"Led my team in developing an autonomous robot, in a team of 5 students, to compete against more than 120 engineering students to play catch the flag game, where we ranked 3/25.\n","date":1444348800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1444348800,"objectID":"a78a4a4198c0f530bdec0e556e7bec59","permalink":"/project/catch_the_flag/","publishdate":"2015-10-09T00:00:00Z","relpermalink":"/project/catch_the_flag/","section":"project","summary":"Led my team in developing an autonomous robot, in a team of 5 students, to compete against more than 120 engineering students to play catch the flag game, where we ranked 3/25.","tags":[],"title":"Catch the Flag Robot","type":"project"},{"authors":[],"categories":[],"content":"Implemented a modified version of this game with integrated account management system.\n","date":1412812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1412812800,"objectID":"bbbef46a416c49c3336cf24ad065881b","permalink":"/project/bomberman/","publishdate":"2014-10-09T00:00:00Z","relpermalink":"/project/bomberman/","section":"project","summary":"Implemented a modified version of this game with integrated account management system.","tags":[],"title":"Bomberman Game","type":"project"}]